# News_Search_engine
Using Python to achieve a News_Search_engine.

新闻检索系统：定向采集不少于 4 个中文社会新闻网站或频道，实现这些网站新闻信息及评论信息的自动爬取、抽取、索引和检索。 本项目未使用 lucene，Goose 等成熟开源框架。

1.新闻爬取
该模块针对搜狐，网易，腾讯三大主流新闻网站及官方的参考消息网站进行了新闻获取。并基于其网站结构，设计了不同的爬取模式。

2.索引构建

（1）分词，我们借助开源的 jieba 中文分词组件来完成， jieba 分词能够将一个中文句子切成一个个词项，这样就可以统计 tf, df 了；

（2）去停用词，去停词的步骤在 jieba 分词之后完成；

（3）倒排记录表存储，词典用 B-树或 hash 存储，倒排记录表用邻接链表存储方式，这样能大大减少存储空间。倒排索引构建算法使用内存式单遍扫描索引构建方法（SPIMI），就是依次对每篇新闻进行分词，如果出现新的词项则插入到词典中，否则将该文档的信息追加到词项对应的倒排记录表中。 

 3.检索排序
 
（1）按相关度

按新闻的相关度排序，相关度越高的新闻排名越高。检索模型中检索效果最好的是基于概率的 BM25 模型。

（2）按时间

类似的，我们还可以对所有文档按时间先后顺序排序，越新鲜新闻排名越高。

（3）按热度

按新闻的热度排序，越热门的新闻排名越高。关于热度公式，我们认为主要和三个因素有关：相关度，这个不需要过多解释，列出的新闻一定要和查询相关；用户评论数，评论数和点击数是呈正相关的，若一篇新闻下的评论越多，则表明该新闻更受用户关注；同时也要考虑时间因素，时间越久远，新闻的热度就会越低。所以热度公式是 BM25 打分、评论数打分和时间打分的一个综合。

4.用户接口

（1）查询自动补全

1）用户在输入框输入搜索内容时，根据用户的输入内容，自动完成数据匹配和前端展示，最多展示十条。

2）用户可以通过键盘方向键浏览。

3）用户可以通过鼠标的点击和键盘的回车选中需要的数据项并更新显示在输入框中，同时实现搜索。

（2）实时 snippet 生成

该模块给用户提供了一个更加方便快速的视角查看检索结果中检索词出现的语境和上下文，从而快速排查是否为所需信息。其核心思想是对检索词所在句子进行整合和凸显。

（3）相关搜索推荐

该模块针对用户的搜索给用户提供相关联的搜索词或者用户可能想了解的相关信息。其核心思想是提取用户检索结果中除检索词之外的关键词。具体做法如下：

1）提取出前二十个检索结果的标题，若检索结果没有 20 条则取全部检索结果的标题；

2）用 TextRank 算法对所取标题组成的整个文本进行关键词的抽取；

3）按照重要值取前 10 个关键词作为推荐搜索词。

（4）热点新闻推荐

该算法与按热度排序的算法相似，只是去掉与查询相关度的信息，表示为评论数、新闻时间和当前时间的差值的倒数线性加权。另外与按热度排序的算法不同的是，按热度排序的算法应用于检索出的相关文档，而该算法应用于全部的文档，选出评分最高的前 K 个新闻放在主页上显示。

（5）相似新闻推荐

jieba 分词组件自带关键词提取功能，并能返回关键词的 tf*idf 值。所以对每篇新闻，我们先提取 tf*idf 得分最高的前 25 个关键词，用这 25 个关键词的 tf*idf 值作为文档的向量表示。由此能够得到一个 1000*m 的文档词项矩阵 M，矩阵每行表示一个文档，每列表示一个词项， m 为 1000 个文档的所有互异的关键词（大概 10000 个）。 M 是稀疏矩阵。得到文档词项矩阵 M 之后，我们利用 sklearn 的 pairwise_distances 函数计算 M 中行向量之间的 cosine 相似度，对每个文档，得到与其最相似的前 5 篇新闻 id，并把结果写入数据库。

（6）情感分析

该模块给用户提供了对每条新闻评论的情感极性分析，并且对每篇新闻所有新闻的总体评价极性趋势以及情绪波动情况进行了统计分析。其核心思想是利用情感词典给评论进行情感分析。

5.前端模块

前端部分采用 flask 框架搭建，用 bootstrap 框架进行美化，模板匹配采用jinja2 模板引擎搜索界面风格及配色模仿谷歌，前端效果展示见视频。
